additionalPrometheusRulesMap:
  openstack-resource-alerts:
    groups:
      - name: Compute Resource Alerts
        rules:
          - alert: AbnormalInstanceFailures
            expr: |
              count(count(last_over_time(openstack_nova_server_status{status=~"BUILD|ERROR"}[60m])) by (id)) /
              count(count(last_over_time(openstack_nova_server_status{status="ACTIVE"}[60m])) by (id)) * 100 >= 20
            labels:
              severity: critical
            annotations:
              summary: "Instance build failure rate is abnormally high"
              description: |
                This indicates a major problem building compute instances.
                View logs and take action to resolve the build failures.
          - alert: InstancesStuckInFailureState
            expr: sum(count_over_time(openstack_nova_server_status{status=~"BUILD|ERROR"}[1h])) > 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: "Instances stuck in failure state for a prolonged period"
              description: |
                There are instances stuck in a building or error state for a prolonged period
                that need to be cleaned up.
      - name: Image Resource Alerts
        rules:
          - alert: AbnormalImageFailures
            expr: |
              count(count(last_over_time(openstack_glance_image_created_at{status!~"active|deactivated"}[60m])) by (id)) /
              count(count(last_over_time(openstack_glance_image_created_at{status="active"}[60m])) by (id)) * 100 >= 20
            labels:
              severity: critical
            annotations:
              summary: "Image create failure rate is abnormally high"
              description: |
                This indicates a major problem creating images.
                View logs and take action to resolve the build failures.
          - alert: ImagesStuckInFailureState
            expr: sum(count_over_time(openstack_glance_image_created_at{status="failure"}[1h])) > 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: "Images stuck in failure state for a prolonged period"
              description: |
                There are images stuck in a failure state for a prolonged period
                that need to be cleaned up.
      - name: Octavia Resource Alerts
        rules:
          - alert: LoadbalancersInErrorCritical
            expr: count(openstack_loadbalancer_loadbalancer_status{provisioning_status="ERROR"}) / count(openstack_loadbalancer_loadbalancer_status) * 100 > 50
            labels:
              severity: critical
            annotations:
              summary: "More than 50% of the loadbalancers are in error state"
              description: |
                This likely indicates a cluster wide problem either with networking, health manager operations or building amphora vm's and needs to be investigated.
          - alert: LoadbalancersInError
            expr: sum(count_over_time(openstack_loadbalancer_loadbalancer_status{provisioning_status="ERROR"}[1h])) > 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: "Loadbalancers stuck in error state for a prolonged period"
              description: |
                This could indicate problems building load balancers and should be investigated.
  blackbox-alerts:
    groups:
      - name: Blackbox Alerts
        rules:
          - alert: TLS certificate expiring
            expr: (probe_ssl_earliest_cert_expiry - time()) / 86400 < 30
            labels:
              severity: warning
            annotations:
              summary: "SSL certificate will expire soon on (instance {{ $labels.instance }})"
              description: |
                SSL certificate expires within 30 days.
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
          - alert: TLS certificate expiring
            expr: (probe_ssl_earliest_cert_expiry - time()) / 86400 < 15
            labels:
              severity: critical
            annotations:
              summary: "SSL certificate will expire soon on (instance {{ $labels.instance }})"
              description: |
                SSL certificate expires within 15 days.
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
          - alert: Service Down
            expr: probe_success == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Service probe has failed for more than two minutes on (instance {{ $labels.instance }})"
              description: |
                Service probe has failed for more than two minutes.
                LABELS = {{ $labels }}
  volume-alerts:
    groups:
      - name: Volume Alerts
        rules:
          - alert: KubernetesVolumeOutOfDiskSpace
            expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 20
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: "Kubernetes Volume out of disk space (instance {{ $labels.instance }})"
              description: |
                Volume is almost full (< 20% left).
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
  backup-alerts:
    groups:
      - name: OVN backup alerts
        rules:
          - alert: ovnBackupUploadWarning
            expr: time() - upload_pairs_success_timestamp{job="ovn-backup"} > 21600
            for: 1h
            labels:
              severity: warning
            annotations:
              summary: "Last OVN backup not uploaded within 1 hour of scheduled run"
              description: |
                Last OVN backup not uploaded within 1 hour of scheduled run.
          - alert: ovnBackupUploadCritical
            expr: time() - upload_pairs_success_timestamp{job="ovn-backup"} > 43200
            for: 1h
            labels:
              severity: critical
            annotations:
              summary: "Second successive OVN backup not uploaded within 1 hour of scheduled run"
              description: |
                Second successive OVN backup not uploaded within 1 hour of scheduled run.
          - alert: ovnBackupDiskUsageWarning
            expr: disk_used_percent_gauge{job="ovn-backup"} > 80
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: "OVN backup volume >= 80% disk usage"
              description: |
                OVN backup volume >= 80% disk usage.
          - alert: ovnBackupDiskUsageCritical
            expr: disk_used_percent_gauge{job="ovn-backup"} > 90
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: "OVN backup volume >= 90% disk usage"
              description: |
                OVN backup volume >= 90% disk usage.
      - name: MariaDB backup alerts
        rules:
          - alert: mariadbBackupWarning
            expr: |
              time() - kube_cronjob_status_last_successful_time{cronjob="mariadb-backup", namespace="openstack"} > 21900 or
              time() - kube_cronjob_status_last_successful_time{cronjob="mariadb-backup", namespace="grafana"} > 86700
            for: 1h
            labels:
              severity: warning
            annotations:
              summary: "Last MariaDB backup not successful within 1 hour of scheduled run"
              description: |
                Last MariaDB backup not successful within 1 hour of scheduled run.
          - alert: mariadbBackupCritical
            expr: |
              time() - kube_cronjob_status_last_successful_time{cronjob="mariadb-backup", namespace="openstack"} > 43200 or
              time() - kube_cronjob_status_last_successful_time{cronjob="mariadb-backup", namespace="grafana"} > 172800
            for: 1h
            labels:
              severity: critical
            annotations:
              summary: "Second successive MariaDB backup not successful within 1 hour of scheduled run"
              description: |
                Second successive MariaDB backup not successful within 1 hour of scheduled run.
  fluentbit-servicemonitor-alert:
    groups:
      - name: fluentbit serviceMonitor alert
        rules:
          - alert: MissingFluentbitServiceMonitor
            expr: count(up{job="fluentbit-fluent-bit"}) == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "ServiceMonitor 'fluentbit-fluent-bit' is either down or missing."
              description: |
                Check if the Fluentbit ServiceMonitor is properly configured and deployed.
